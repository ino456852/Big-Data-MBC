{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0dfbde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>channelTitle</th>\n",
       "      <th>categoryId</th>\n",
       "      <th>view_count</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>channelId</th>\n",
       "      <th>trending_date2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[신병] 물자창고</td>\n",
       "      <td>장삐쭈</td>\n",
       "      <td>23</td>\n",
       "      <td>1893473</td>\n",
       "      <td>38249</td>\n",
       "      <td>730</td>\n",
       "      <td>8595</td>\n",
       "      <td>UChbE5OZQ6dRHECsX0tEPEZQ</td>\n",
       "      <td>2021-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RAIN(비) - 나로 바꾸자 Switch to me (duet with JYP) MV</td>\n",
       "      <td>RAIN's Official Channel</td>\n",
       "      <td>10</td>\n",
       "      <td>2600864</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20129</td>\n",
       "      <td>UCxXgIeE5hxWxHG6dz9Scg2w</td>\n",
       "      <td>2021-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020년 제야의 종 온라인 타종행사 | 보신각 현장 행사는 진행하지 않습니다.</td>\n",
       "      <td>서울시 · Seoul</td>\n",
       "      <td>29</td>\n",
       "      <td>347049</td>\n",
       "      <td>3564</td>\n",
       "      <td>120</td>\n",
       "      <td>178</td>\n",
       "      <td>UCZUPZW5idAxYp-Asj__lVAA</td>\n",
       "      <td>2021-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>고기남자의 칠면조 파티</td>\n",
       "      <td>고기남자 MeatMan</td>\n",
       "      <td>26</td>\n",
       "      <td>528458</td>\n",
       "      <td>15372</td>\n",
       "      <td>280</td>\n",
       "      <td>3470</td>\n",
       "      <td>UCT3CumbFIJiW33uq0UI3zlg</td>\n",
       "      <td>2021-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>골목 3mc를 분노하게 만든 마음고생이 심했을 공릉 백반집 사장님의 푸념?! [예능...</td>\n",
       "      <td>스브스밥집</td>\n",
       "      <td>24</td>\n",
       "      <td>494904</td>\n",
       "      <td>3918</td>\n",
       "      <td>111</td>\n",
       "      <td>3142</td>\n",
       "      <td>UCdWgRSfttvDucq4ApcCg5Mw</td>\n",
       "      <td>2021-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title             channelTitle  \\\n",
       "0                                          [신병] 물자창고                      장삐쭈   \n",
       "1   RAIN(비) - 나로 바꾸자 Switch to me (duet with JYP) MV  RAIN's Official Channel   \n",
       "2       2020년 제야의 종 온라인 타종행사 | 보신각 현장 행사는 진행하지 않습니다.              서울시 · Seoul   \n",
       "3                                       고기남자의 칠면조 파티             고기남자 MeatMan   \n",
       "4  골목 3mc를 분노하게 만든 마음고생이 심했을 공릉 백반집 사장님의 푸념?! [예능...                    스브스밥집   \n",
       "\n",
       "   categoryId  view_count  likes  dislikes  comment_count  \\\n",
       "0          23     1893473  38249       730           8595   \n",
       "1          10     2600864      0         0          20129   \n",
       "2          29      347049   3564       120            178   \n",
       "3          26      528458  15372       280           3470   \n",
       "4          24      494904   3918       111           3142   \n",
       "\n",
       "                  channelId trending_date2  \n",
       "0  UChbE5OZQ6dRHECsX0tEPEZQ     2021-01-01  \n",
       "1  UCxXgIeE5hxWxHG6dz9Scg2w     2021-01-01  \n",
       "2  UCZUPZW5idAxYp-Asj__lVAA     2021-01-01  \n",
       "3  UCT3CumbFIJiW33uq0UI3zlg     2021-01-01  \n",
       "4  UCdWgRSfttvDucq4ApcCg5Mw     2021-01-01  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/Datamanim/datarepo/main/youtube/youtube.csv\",index_col=0)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97841f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 인기동영상 제작횟수가 많은 채널 상위 10개명을 출력하라 (날짜기준, 중복포함)\n",
    "top_channels = df[\"channelTitle\"].value_counts(ascending=False).index.tolist() # value_counts로 인덱스로 들어간 채널명을 가져와 리스트로 변경\n",
    "top_channels\n",
    "# 논란으로 인기동영상이 된 케이스를 확인하고 싶다. dislikes수가 like 수보다 높은 동영상을 제작한 채널을 모두 출력하라\n",
    "df.query('dislikes > likes')['channelTitle'].unique() # 쿼리 함수, 고유값찾기\n",
    "# 채널명을 바꾼 케이스가 있는지 확인하고 싶다. channelId의 경우 고유값이므로 이를 통해 채널명을 한번이라도 바꾼 채널의 갯수를 구하여라\n",
    "change = df.groupby('channelId')['channelTitle'].nunique() # 채널id별 채널명의 고유값 갯수 가져오고 채널id가 2개 이상인 값 추출, 그 값의 length\n",
    "change_channel = change[change > 1]\n",
    "len(change_channel)\n",
    "# 일요일에 인기있었던 영상들중 가장많은 영상 종류(categoryId)는 무엇인가?\n",
    "df['trending_date'] = pd.to_datetime(df['trending_date2'], format='%Y-%m-%d') # sql에 TO_DATE와 유사한 기능 yyyy면 y가 대문자\n",
    "sunday_df = df[df['trending_date'].dt.weekday == 6] # dt.weekday()는 0이 월요일, 6이 일요일 tending_date가 dt.weekday 6 인 값들\n",
    "sundday_categoryId = sunday_df['categoryId'].value_counts() # 6인 값들의 채널id들\n",
    "sundday_categoryId.head(1)\n",
    "# 각 요일별 인기 영상들의 categoryId는 각각 몇개 씩인지 하나의 데이터 프레임으로 표현하라\n",
    "df['tranding_date'] = pd.to_datetime(df['trending_date2'], format='%Y-%m-%d') # pd.to_datetime으로 변환\n",
    "df['day_name'] = df['tranding_date'].dt.day_name() # dt.day_name으로 요일이름 가져오기\n",
    "group = df.groupby(['day_name', 'categoryId']).size().reset_index(name=\"count\")# 요일이름 채널 아이디의 사이즈 출력하고 인덱스로 바꾼뒤 인덱스 초기화 후 count 컬럼 생성\n",
    "pivot_table = group.pivot(index='day_name', columns='categoryId', values='count') # 피봇으로 인덱스,컬럼,값 지정\n",
    "pivot_table.transpose() # 채널id와 요일이름 위치변경\n",
    "# 댓글의 수로 (comment_count) 영상 반응에 대한 판단을 할 수 있다. viewcount대비 댓글수가 가장 높은 영상을 확인하라 (view_count값이 0인 경우는 제외한다)\n",
    "zero = df.loc[df['view_count'] != 0] # 조회수가 0인 값 제외\n",
    "comment = zero['comment_count'] / zero['view_count'] # 비율 계산 \n",
    "best_index = comment.sort_values(ascending=False).index[0] # view카운트 대비 댓글수가 가장 높은 영상의 채널의 인덱스\n",
    "result = df.loc[best_index, 'title'] # 해당 인덱스의 제목 출력\n",
    "result\n",
    "# 댓글의 수로 (comment_count) 영상 반응에 대한 판단을 할 수 있다.viewcount대비 댓글수가 가장 낮은 영상을 확인하라 (view_counts, ratio값이 0인경우는 제외한다.)\n",
    "zero = df.loc[df['view_count'] != 0]\n",
    "comment = zero['comment_count'] / zero['view_count']\n",
    "ratio = comment[comment != 0] # 비율 계산 후 0이 아닌값\n",
    "min_ratio = ratio.idxmin() # 0이 아닌 값중에 제일 낮은 값 idxmin() 인덱스 중 최소값\n",
    "title = zero.loc[min_ratio, 'title'] \n",
    "title\n",
    "# like 대비 dislike의 수가 가장 적은 영상은 무엇인가? (like, dislike 값이 0인경우는 제외한다)\n",
    "zero = df.loc[(df['likes'] != 0) & (df['dislikes'] != 0),['likes', 'dislikes', 'title']] # loc의 and 연산 0제외\n",
    "ratio = zero['dislikes'] / zero['likes'] # 비율 계산\n",
    "min_likes = ratio.idxmin() # 인덱스 최소값\n",
    "title = zero.loc[min_likes,'title'] # 인덱스 최소값 영상의 제목\n",
    "title\n",
    "# 가장많은 트렌드 영상을 제작한 채널의 이름은 무엇인가? (날짜기준, 중복포함)\n",
    "best_create = df['channelId'].value_counts().index[0]  # 채널id가 가장 많은 인덱스\n",
    "title = df.loc[df['channelId']==best_create,'channelTitle'].unique() # id가 많은, 영사잉 많은 채널 id의 채널 이름 , 중복제거\n",
    "title\n",
    "# 20회(20일)이상 인기동영상 리스트에 포함된 동영상의 숫자는?\n",
    "best_video = (df[['title','channelTitle']].value_counts() >= 20).sum()\n",
    "best_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c9ca75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>channelTitle</th>\n",
       "      <th>categoryId</th>\n",
       "      <th>view_count</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>channelId</th>\n",
       "      <th>trending_date2</th>\n",
       "      <th>trending_date</th>\n",
       "      <th>tranding_date</th>\n",
       "      <th>day_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RAIN(비) - 나로 바꾸자 Switch to me (duet with JYP) MV</td>\n",
       "      <td>RAIN's Official Channel</td>\n",
       "      <td>10</td>\n",
       "      <td>2600864</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20129</td>\n",
       "      <td>UCxXgIeE5hxWxHG6dz9Scg2w</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[아이유의 팔레트] 팔레트에 '있지' (With ITZY) Ep.4</td>\n",
       "      <td>이지금 [IU Official]</td>\n",
       "      <td>24</td>\n",
       "      <td>2420537</td>\n",
       "      <td>200301</td>\n",
       "      <td>956</td>\n",
       "      <td>14641</td>\n",
       "      <td>UC3SyT4_WLHzN7JmHQwKQZww</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[신병] 물자창고</td>\n",
       "      <td>장삐쭈</td>\n",
       "      <td>23</td>\n",
       "      <td>1893473</td>\n",
       "      <td>38249</td>\n",
       "      <td>730</td>\n",
       "      <td>8595</td>\n",
       "      <td>UChbE5OZQ6dRHECsX0tEPEZQ</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>나 숙취 있어! 알딸딸해! 필름 끊겼어를 영어로 어떻게 할까요?</td>\n",
       "      <td>Sarah Kim</td>\n",
       "      <td>27</td>\n",
       "      <td>1358098</td>\n",
       "      <td>8224</td>\n",
       "      <td>820</td>\n",
       "      <td>1406</td>\n",
       "      <td>UCMXFwld5hCpMc2-49cndljA</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(EN/CN/ID) 월드스타 한 분 더 모셨습니다. 비x박진영 &amp; 싸이, 비주얼 가...</td>\n",
       "      <td>시즌비시즌 Season B Season</td>\n",
       "      <td>24</td>\n",
       "      <td>1274464</td>\n",
       "      <td>26660</td>\n",
       "      <td>368</td>\n",
       "      <td>2701</td>\n",
       "      <td>UCZf4ZESHAIuRtZ-eoMSL97A</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>답답한 집콕.. 2020년은 예능으로 존버(존중하며 버팀)했다 MBC 연예대상 하이...</td>\n",
       "      <td>14F 일사에프</td>\n",
       "      <td>26</td>\n",
       "      <td>1001581</td>\n",
       "      <td>9462</td>\n",
       "      <td>337</td>\n",
       "      <td>1684</td>\n",
       "      <td>UCLKuglhGlMmDteQKoniENIQ</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[미스트롯2] 많은 참가자가 라이벌로 뽑은 명실상부 트롯 천재! 전유진이 부르는 '...</td>\n",
       "      <td>TV CHOSUN JOY</td>\n",
       "      <td>24</td>\n",
       "      <td>682608</td>\n",
       "      <td>7435</td>\n",
       "      <td>434</td>\n",
       "      <td>1943</td>\n",
       "      <td>UCYeeEwH_s9yD9HQe4e2JuBw</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>고기남자의 칠면조 파티</td>\n",
       "      <td>고기남자 MeatMan</td>\n",
       "      <td>26</td>\n",
       "      <td>528458</td>\n",
       "      <td>15372</td>\n",
       "      <td>280</td>\n",
       "      <td>3470</td>\n",
       "      <td>UCT3CumbFIJiW33uq0UI3zlg</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>골목 3mc를 분노하게 만든 마음고생이 심했을 공릉 백반집 사장님의 푸념?! [예능...</td>\n",
       "      <td>스브스밥집</td>\n",
       "      <td>24</td>\n",
       "      <td>494904</td>\n",
       "      <td>3918</td>\n",
       "      <td>111</td>\n",
       "      <td>3142</td>\n",
       "      <td>UCdWgRSfttvDucq4ApcCg5Mw</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020년 제야의 종 온라인 타종행사 | 보신각 현장 행사는 진행하지 않습니다.</td>\n",
       "      <td>서울시 · Seoul</td>\n",
       "      <td>29</td>\n",
       "      <td>347049</td>\n",
       "      <td>3564</td>\n",
       "      <td>120</td>\n",
       "      <td>178</td>\n",
       "      <td>UCZUPZW5idAxYp-Asj__lVAA</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title             channelTitle  \\\n",
       "1   RAIN(비) - 나로 바꾸자 Switch to me (duet with JYP) MV  RAIN's Official Channel   \n",
       "7              [아이유의 팔레트] 팔레트에 '있지' (With ITZY) Ep.4        이지금 [IU Official]   \n",
       "0                                          [신병] 물자창고                      장삐쭈   \n",
       "9                나 숙취 있어! 알딸딸해! 필름 끊겼어를 영어로 어떻게 할까요?                Sarah Kim   \n",
       "5  (EN/CN/ID) 월드스타 한 분 더 모셨습니다. 비x박진영 & 싸이, 비주얼 가...    시즌비시즌 Season B Season   \n",
       "8  답답한 집콕.. 2020년은 예능으로 존버(존중하며 버팀)했다 MBC 연예대상 하이...                 14F 일사에프   \n",
       "6  [미스트롯2] 많은 참가자가 라이벌로 뽑은 명실상부 트롯 천재! 전유진이 부르는 '...            TV CHOSUN JOY   \n",
       "3                                       고기남자의 칠면조 파티             고기남자 MeatMan   \n",
       "4  골목 3mc를 분노하게 만든 마음고생이 심했을 공릉 백반집 사장님의 푸념?! [예능...                    스브스밥집   \n",
       "2       2020년 제야의 종 온라인 타종행사 | 보신각 현장 행사는 진행하지 않습니다.              서울시 · Seoul   \n",
       "\n",
       "   categoryId  view_count   likes  dislikes  comment_count  \\\n",
       "1          10     2600864       0         0          20129   \n",
       "7          24     2420537  200301       956          14641   \n",
       "0          23     1893473   38249       730           8595   \n",
       "9          27     1358098    8224       820           1406   \n",
       "5          24     1274464   26660       368           2701   \n",
       "8          26     1001581    9462       337           1684   \n",
       "6          24      682608    7435       434           1943   \n",
       "3          26      528458   15372       280           3470   \n",
       "4          24      494904    3918       111           3142   \n",
       "2          29      347049    3564       120            178   \n",
       "\n",
       "                  channelId trending_date2 trending_date tranding_date  \\\n",
       "1  UCxXgIeE5hxWxHG6dz9Scg2w     2021-01-01    2021-01-01    2021-01-01   \n",
       "7  UC3SyT4_WLHzN7JmHQwKQZww     2021-01-01    2021-01-01    2021-01-01   \n",
       "0  UChbE5OZQ6dRHECsX0tEPEZQ     2021-01-01    2021-01-01    2021-01-01   \n",
       "9  UCMXFwld5hCpMc2-49cndljA     2021-01-01    2021-01-01    2021-01-01   \n",
       "5  UCZf4ZESHAIuRtZ-eoMSL97A     2021-01-01    2021-01-01    2021-01-01   \n",
       "8  UCLKuglhGlMmDteQKoniENIQ     2021-01-01    2021-01-01    2021-01-01   \n",
       "6  UCYeeEwH_s9yD9HQe4e2JuBw     2021-01-01    2021-01-01    2021-01-01   \n",
       "3  UCT3CumbFIJiW33uq0UI3zlg     2021-01-01    2021-01-01    2021-01-01   \n",
       "4  UCdWgRSfttvDucq4ApcCg5Mw     2021-01-01    2021-01-01    2021-01-01   \n",
       "2  UCZUPZW5idAxYp-Asj__lVAA     2021-01-01    2021-01-01    2021-01-01   \n",
       "\n",
       "  day_name  \n",
       "1   Friday  \n",
       "7   Friday  \n",
       "0   Friday  \n",
       "9   Friday  \n",
       "5   Friday  \n",
       "8   Friday  \n",
       "6   Friday  \n",
       "3   Friday  \n",
       "4   Friday  \n",
       "2   Friday  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top_view= df['view_count'].head(10).sort_values(ascending=False).index\n",
    "\n",
    "top_view_rows = df.loc[top_view]\n",
    "display(top_view_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2519ddcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channelid</th>\n",
       "      <th>subcnt</th>\n",
       "      <th>viewcnt</th>\n",
       "      <th>videocnt</th>\n",
       "      <th>ct</th>\n",
       "      <th>channelname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UCkQCwnkQfgSuPTTnw_Y7v7w</td>\n",
       "      <td>1310000</td>\n",
       "      <td>410238653</td>\n",
       "      <td>736</td>\n",
       "      <td>2021-09-30 03:01:03</td>\n",
       "      <td>꽈뚜룹</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UCkQCwnkQfgSuPTTnw_Y7v7w</td>\n",
       "      <td>1310000</td>\n",
       "      <td>412531322</td>\n",
       "      <td>736</td>\n",
       "      <td>2021-09-30 09:01:03</td>\n",
       "      <td>꽈뚜룹</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UCkQCwnkQfgSuPTTnw_Y7v7w</td>\n",
       "      <td>1310000</td>\n",
       "      <td>412531322</td>\n",
       "      <td>735</td>\n",
       "      <td>2021-09-30 15:01:03</td>\n",
       "      <td>꽈뚜룹</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UCkQCwnkQfgSuPTTnw_Y7v7w</td>\n",
       "      <td>1310000</td>\n",
       "      <td>412531322</td>\n",
       "      <td>737</td>\n",
       "      <td>2021-09-30 21:01:03</td>\n",
       "      <td>꽈뚜룹</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UCkQCwnkQfgSuPTTnw_Y7v7w</td>\n",
       "      <td>1320000</td>\n",
       "      <td>412531322</td>\n",
       "      <td>737</td>\n",
       "      <td>2021-10-01 03:01:04</td>\n",
       "      <td>꽈뚜룹</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  channelid   subcnt    viewcnt  videocnt  \\\n",
       "0  UCkQCwnkQfgSuPTTnw_Y7v7w  1310000  410238653       736   \n",
       "1  UCkQCwnkQfgSuPTTnw_Y7v7w  1310000  412531322       736   \n",
       "2  UCkQCwnkQfgSuPTTnw_Y7v7w  1310000  412531322       735   \n",
       "3  UCkQCwnkQfgSuPTTnw_Y7v7w  1310000  412531322       737   \n",
       "4  UCkQCwnkQfgSuPTTnw_Y7v7w  1320000  412531322       737   \n",
       "\n",
       "                    ct channelname  \n",
       "0  2021-09-30 03:01:03         꽈뚜룹  \n",
       "1  2021-09-30 09:01:03         꽈뚜룹  \n",
       "2  2021-09-30 15:01:03         꽈뚜룹  \n",
       "3  2021-09-30 21:01:03         꽈뚜룹  \n",
       "4  2021-10-01 03:01:04         꽈뚜룹  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>videopk</th>\n",
       "      <th>viewcnt</th>\n",
       "      <th>likecnt</th>\n",
       "      <th>dislikecnt</th>\n",
       "      <th>favoritecnt</th>\n",
       "      <th>cmcnt</th>\n",
       "      <th>ct</th>\n",
       "      <th>videoname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c5JQp6xafqc</td>\n",
       "      <td>1667010</td>\n",
       "      <td>30474</td>\n",
       "      <td>706</td>\n",
       "      <td>0</td>\n",
       "      <td>6587</td>\n",
       "      <td>2021-10-10 15:20:03</td>\n",
       "      <td>공범 EP1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c5JQp6xafqc</td>\n",
       "      <td>1669089</td>\n",
       "      <td>30495</td>\n",
       "      <td>707</td>\n",
       "      <td>0</td>\n",
       "      <td>6589</td>\n",
       "      <td>2021-10-10 15:30:03</td>\n",
       "      <td>공범 EP1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c5JQp6xafqc</td>\n",
       "      <td>1674759</td>\n",
       "      <td>30522</td>\n",
       "      <td>711</td>\n",
       "      <td>0</td>\n",
       "      <td>6596</td>\n",
       "      <td>2021-10-10 15:40:02</td>\n",
       "      <td>공범 EP1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c5JQp6xafqc</td>\n",
       "      <td>1677026</td>\n",
       "      <td>30555</td>\n",
       "      <td>712</td>\n",
       "      <td>0</td>\n",
       "      <td>6604</td>\n",
       "      <td>2021-10-10 15:50:03</td>\n",
       "      <td>공범 EP1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c5JQp6xafqc</td>\n",
       "      <td>1681824</td>\n",
       "      <td>30585</td>\n",
       "      <td>713</td>\n",
       "      <td>0</td>\n",
       "      <td>6600</td>\n",
       "      <td>2021-10-10 16:00:03</td>\n",
       "      <td>공범 EP1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       videopk  viewcnt  likecnt  dislikecnt  favoritecnt  cmcnt  \\\n",
       "0  c5JQp6xafqc  1667010    30474         706            0   6587   \n",
       "1  c5JQp6xafqc  1669089    30495         707            0   6589   \n",
       "2  c5JQp6xafqc  1674759    30522         711            0   6596   \n",
       "3  c5JQp6xafqc  1677026    30555         712            0   6604   \n",
       "4  c5JQp6xafqc  1681824    30585         713            0   6600   \n",
       "\n",
       "                    ct videoname  \n",
       "0  2021-10-10 15:20:03    공범 EP1  \n",
       "1  2021-10-10 15:30:03    공범 EP1  \n",
       "2  2021-10-10 15:40:02    공범 EP1  \n",
       "3  2021-10-10 15:50:03    공범 EP1  \n",
       "4  2021-10-10 16:00:03    공범 EP1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "channel =pd.read_csv('https://raw.githubusercontent.com/Datamanim/datarepo/main/youtube/channelInfo.csv')\n",
    "video =pd.read_csv('https://raw.githubusercontent.com/Datamanim/datarepo/main/youtube/videoInfo.csv')\n",
    "display(channel.head())\n",
    "display(video.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5b4cf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>viewcnt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>videoname</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>공범 EP1</th>\n",
       "      <td>13298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>공범 EP2</th>\n",
       "      <td>10300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>공범 EP3</th>\n",
       "      <td>9927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>공범 EP4</th>\n",
       "      <td>9824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>공범 EP5</th>\n",
       "      <td>10824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>공범 EP6</th>\n",
       "      <td>14141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>공범 EP7</th>\n",
       "      <td>26949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>공범 EP8</th>\n",
       "      <td>89147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           viewcnt\n",
       "videoname         \n",
       "공범 EP1       13298\n",
       "공범 EP2       10300\n",
       "공범 EP3        9927\n",
       "공범 EP4        9824\n",
       "공범 EP5       10824\n",
       "공범 EP6       14141\n",
       "공범 EP7       26949\n",
       "공범 EP8       89147"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 각 데이터의 ‘ct’컬럼을 시간으로 인식할수 있게 datatype을 변경하고 video 데이터의 videoname의 각 value 마다 몇개의 데이터씩 가지고 있는지 확인하라\n",
    "# channel['ct'] = pd.to_datetime(channel['ct']) # to_datetime\n",
    "# # channel['ct'].dtypes\n",
    "# video['videoname'].value_counts()\n",
    "# 수집된 각 video의 가장 최신화 된 날짜의 viewcount값을 출력하라\n",
    "# ans2 = video[['viewcnt','videoname','ct']].sort_values(by='viewcnt', ascending=False)\\\n",
    "#     .drop_duplicates(subset='videoname', keep='first')\\\n",
    "#     .reset_index(drop=True) # 3컬럼을 가져와 viewcnt 기준으로 내림차순 정렬 후 videoname의 중복제거,첫번째 값만 남김 인덱스 초기화 후 인덱스 컬럼 삭제\n",
    "# ans2\n",
    "# Channel 데이터중 2021-10-03일 이후 각 채널의 처음 기록 됐던 구독자 수(subcnt)를 출력하라\n",
    "# channel['ct'] = pd.to_datetime(channel['ct'])  # ct를 datetime으로 변환\n",
    "# channel_after = channel[channel['ct'] >= '2021-10-03'] # 2021-10-03 이후 데이터만 필터링\n",
    "# channel_sorted = channel_after.sort_values(by='ct') # ct 기준으로 오름차순 정렬 (먼저 수집된 게 위로)\n",
    "# channel_first = channel_sorted.drop_duplicates(subset='channelname', keep='first') # 채널마다 처음 나오는 값만 남김\n",
    "# ans3 = channel_first[['channelname', 'subcnt']].reset_index(drop=True) # 컬럼 정리\n",
    "# ans3\n",
    "# 각채널의 2021-10-03 03:00:00 ~ 2021-11-01 15:00:00 까지 구독자수 (subcnt) 의 증가량을 구하여라\n",
    "# channel['ct'] = pd.to_datetime(channel['ct']) # 날짜 형식 변환\n",
    "# channel_range = channel[(channel['ct'] >= '2021-10-03 03:00:00') &  (channel['ct'] <= '2021-11-01 15:00:00')]  # 해당 날짜 범위로 필터링\n",
    "# channel_sorted = channel_range.sort_values(by='ct') # 시간순 정렬\n",
    "# grouped = channel_sorted.groupby('channelname')['subcnt'] # 채널별 구독자 수\n",
    "# first = grouped.first() # 제일 먼저 구한 값, 내림차순으로 맨 아래값 시간순으로 처음, 옛날 구독자 수\n",
    "# last = grouped.last() # 마지막 구독자 수, 최근 구독자 수\n",
    "# increase = last - first # 구독자 증가량 계산 (마지막 - 처음)\n",
    "# ans4 = pd.DataFrame({\n",
    "#     'channelname': increase.index,\n",
    "#     'del': increase.values\n",
    "# }).reset_index(drop=True)\n",
    "# ans4\n",
    "# 각 비디오는 10분 간격으로 구독자수, 좋아요, 싫어요수, 댓글수가 수집된것으로 알려졌다. 공범 EP1의 비디오정보 데이터중 수집간격이 5분 이하, 20분이상인 데이터 구간( 해당 시점 전,후) 의 시각을 모두 출력하라\n",
    "# video['ct'] = pd.to_datetime(video['ct'])\n",
    "# ep1 = video[video['videoname'].str.strip() == '공범 EP1'] # 공범 EP1 가져옴\n",
    "# ep1 = ep1.sort_values(by='ct') # 시간 순 정렬\n",
    "# ep1['prev_ct'] = ep1['ct'].shift(1) # 이전 시간 만들기 (한 행씩 밀기)\n",
    "# ep1['gap_min'] = (ep1['ct'] - ep1['prev_ct']).dt.total_seconds() / 60 # 시간 차이 계산 (분 단위)\n",
    "# ans5 = ep1[(ep1['gap_min'] <= 5) | (ep1['gap_min'] >= 20)]# 5분 이하 또는 20분 이상인 구간만 추출\n",
    "# ans5 = ans5[video.columns]  # 원래 컬럼 순서로만 출력\n",
    "# ans5\n",
    "# 각 에피소드의 시작날짜(년-월-일)를 에피소드 이름과 묶어 데이터 프레임으로 만들고 출력하라\n",
    "# video['ct'] = pd.to_datetime(video['ct'])\n",
    "# video_sorted = video.sort_values(by='ct') # 시간 순으로 정렬\n",
    "# video_first = video_sorted.drop_duplicates(subset='videoname', keep='first') # 에피소드 이름마다 가장 처음값만 남기기\n",
    "# video_first['date'] = video_first['ct'].dt.date # 날짜만 추출 (yyyy-mm-dd)\n",
    "# ans6 = video_first[['date', 'videoname']]\n",
    "# ans6\n",
    "# “공범” 컨텐츠의 경우 19:00시에 공개 되는것으로 알려져있다. 공개된 날의 21시의 viewcnt, ct, videoname 으로 구성된 데이터 프레임을 viewcnt를 내림차순으로 정렬하여 출력하라\n",
    "# video['ct'] = pd.to_datetime(video['ct'])\n",
    "# video['hour'] = video['ct'].dt.hour # 시간에서 '시(hour)'만 추출\n",
    "# video_21 = video[(video['videoname'].str.contains('공범')) & (video['hour'] == 21)]\\\n",
    "# .drop_duplicates(subset='videoname', keep='first') # '공범' 포함 + 21시에 수집된 데이터만 선택, videoname 중복제거\n",
    "# ans7 = video_21[['videoname', 'viewcnt', 'ct']]\\\n",
    "#     .sort_values(by='viewcnt', ascending=False).reset_index(drop=True) # 필요한 컬럼만 정리하고 조회수 내림차순 정렬\n",
    "# ans7\n",
    "# video 정보의 가장 최근 데이터들에서 각 에피소드의 싫어요/좋아요 비율을 ratio 컬럼으로 만들고 videoname, ratio로 구성된 데이터 프레임을 ratio를 오름차순으로 정렬하라\n",
    "# video['ct'] = pd.to_datetime(video['ct'])\n",
    "# video_sorted = video.sort_values(by='ct', ascending=False) # 시간 순서로 내림차순 정렬\n",
    "# video_latest = video_sorted.drop_duplicates(subset='videoname', keep='first') # 각 에피소드에서 가장 최근 데이터 하나씩만 남기기\n",
    "# video_latest['ratio'] = video_latest['dislikecnt'] / video_latest['likecnt'] # 비율 계산\n",
    "# ans8 = video_latest[['videoname', 'ratio']].sort_values(by='ratio').reset_index(drop=True) # 필요한 컬럼만 정리하고 오름차순 정렬\n",
    "# ans8\n",
    "# 2021-11-01 00:00:00 ~ 15:00:00까지 각 에피소드별 viewcnt의 증가량을 데이터 프레임으로 만드시오\n",
    "# video['ct'] = pd.to_datetime(video['ct'])\n",
    "# video_range = video[(video['ct'] >= '2021-11-01 00:00:00') & (video['ct'] <= '2021-11-01 15:00:00')] # 원하는 시간 범위로 필터링\n",
    "# video_sorted = video_range.sort_values(by='ct') # 시간 순으로 정렬\n",
    "# grouped = video_sorted.groupby('videoname')['viewcnt'] # 이름별 조회수\n",
    "# first = grouped.first()\n",
    "# last = grouped.last()\n",
    "# increase = last - first # 증가량 계산\n",
    "# ans9 = pd.DataFrame({\n",
    "#     'viewcnt': increase\n",
    "# })\n",
    "# ans9\n",
    "# video 데이터 중에서 중복되는 데이터가 존재한다. 중복되는 각 데이터의 시간대와 videoname 을 구하여라\n",
    "# video['ct'] = pd.to_datetime(video['ct'])\n",
    "# duplicates = video[video.duplicated()] # 완전히 같은 행이 중복된 것 찾기\n",
    "# ans10 = duplicates[['videoname', 'ct']]\n",
    "# ans10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "3189e701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Goals</th>\n",
       "      <th>Years</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Miroslav Klose</td>\n",
       "      <td>16</td>\n",
       "      <td>2002-2006-2010-2014</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ronaldo</td>\n",
       "      <td>15</td>\n",
       "      <td>1998-2002-2006</td>\n",
       "      <td>Brazil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gerd Muller</td>\n",
       "      <td>14</td>\n",
       "      <td>1970-1974</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Just Fontaine</td>\n",
       "      <td>13</td>\n",
       "      <td>1958</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pele</td>\n",
       "      <td>12</td>\n",
       "      <td>1958-1962-1966-1970</td>\n",
       "      <td>Brazil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290</th>\n",
       "      <td>Josip Skoblar</td>\n",
       "      <td>1</td>\n",
       "      <td>1962</td>\n",
       "      <td>Yugoslavia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291</th>\n",
       "      <td>Safet Susic</td>\n",
       "      <td>1</td>\n",
       "      <td>1982-1990</td>\n",
       "      <td>Yugoslavia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1292</th>\n",
       "      <td>Aleksandar Tirnanic</td>\n",
       "      <td>1</td>\n",
       "      <td>1930</td>\n",
       "      <td>Yugoslavia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1293</th>\n",
       "      <td>Djordje Vujadinovic</td>\n",
       "      <td>1</td>\n",
       "      <td>1930</td>\n",
       "      <td>Yugoslavia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>Branko Zebec</td>\n",
       "      <td>1</td>\n",
       "      <td>1954-1958</td>\n",
       "      <td>Yugoslavia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1295 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Player  Goals                Years     Country\n",
       "0          Miroslav Klose     16  2002-2006-2010-2014     Germany\n",
       "1                 Ronaldo     15       1998-2002-2006      Brazil\n",
       "2             Gerd Muller     14            1970-1974     Germany\n",
       "3           Just Fontaine     13                 1958      France\n",
       "4                    Pele     12  1958-1962-1966-1970      Brazil\n",
       "...                   ...    ...                  ...         ...\n",
       "1290        Josip Skoblar      1                 1962  Yugoslavia\n",
       "1291          Safet Susic      1            1982-1990  Yugoslavia\n",
       "1292  Aleksandar Tirnanic      1                 1930  Yugoslavia\n",
       "1293  Djordje Vujadinovic      1                 1930  Yugoslavia\n",
       "1294         Branko Zebec      1            1954-1958  Yugoslavia\n",
       "\n",
       "[1295 rows x 4 columns]"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df= pd.read_csv('https://raw.githubusercontent.com/Datamanim/datarepo/main/worldcup/worldcupgoals.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a0f3fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 주어진 전체 기간의 각 나라별 골득점수 상위 5개 국가와 그 득점수를 데이터프레임형태로 출력하라\n",
    "# df['Goals'] = df['Goals'].fillna(0)\n",
    "# # df['Goals'].isna().sum()\n",
    "# goals = df.groupby('Country')['Goals'].sum()\n",
    "# ans1 = goals.sort_values(ascending=False).head(5).to_frame() # 득점 수 기준으로 내림차순 정렬 후 상위 5개 추출, DataFrame형식변환\n",
    "# ans1\n",
    "# 주어진 전체기간동안 골득점을 한 선수가 가장 많은 나라 상위 5개 국가와 그 선수 숫자를 데이터 프레임 형식으로 출력하라\n",
    "# goals = df[df['Goals'] > 0] # 먼저 Goals > 0인 데이터만 추춣\n",
    "# goals_country = goals.groupby('Country')['Player'].nunique() # 나라별로 득점한 선수 수 세기 선수 중복 제거\n",
    "# ans2 = goals_country.sort_values(ascending=False).head(5).to_frame() # 내림차순 정렬 후 상위 5개 추출, DataFrame형식변환\n",
    "# ans2\n",
    "# Years 컬럼은 년도 -년도 형식으로 구성되어있고, 각 년도는 4자리 숫자이다. 년도 표기가 4자리 숫자로 안된 케이스가 존재한다. 해당 건은 몇건인지 출력하라\n",
    "df['years'] = df['Years'].str.split('-')\n",
    "find = df['years'].apply(lambda x: any((not y.isdigit()) or (len(y) != 4) for y in x)) # split으로 나눈 year가 4자리가 아닌 값\n",
    "# any() 안에 하나라도 true가 있으면 true 반환 str.isdigit() 문자가 하나라도 있으면 False 반환, 공백,마이너스,마침표가 들어가도 False, 여기선 not y니까 True\n",
    "ans3 = find.sum()\n",
    "ans3\n",
    "\n",
    "# **Q3에서 발생한 예외 케이스를 제외한 데이터프레임을 df2라고 정의하고 데이터의 행의 숫자를 출력하라 (아래 문제부터는 df2로 풀이하겠습니다) **\n",
    "# 월드컵 출전횟수를 나타내는 ‘LenCup’ 컬럼을 추가하고 4회 출전한 선수의 숫자를 구하여라\n",
    "# Yugoslavia 국가의 월드컵 출전횟수가 2회인 선수들의 숫자를 구하여라\n",
    "# 2002년도에 출전한 전체 선수는 몇명인가?\n",
    "# 이름에 ‘carlos’ 단어가 들어가는 선수의 숫자는 몇 명인가? (대, 소문자 구분 x)\n",
    "# 월드컵 출전 횟수가 1회뿐인 선수들 중에서 가장 많은 득점을 올렸던 선수는 누구인가?\n",
    "# 월드컵 출전횟수가 1회 뿐인 선수들이 가장 많은 국가는 어디인가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b823040",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df =pd.read_csv('https://raw.githubusercontent.com/Datamanim/datarepo/main/bicycle/seoul_bi.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "b9596bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대여일자별 데이터의 수를 데이터프레임으로 출력하고, 가장 많은 데이터가 있는 날짜를 출력하라\n",
    "# 각 일자의 요일을 표기하고 (‘Monday’ ~’Sunday’) ‘day_name’컬럼을 추가하고 이를 이용하여 각 요일별 이용 횟수의 총합을 데이터 프레임으로 출력하라\n",
    "# 각 요일별 가장 많이 이용한 대여소의 이용횟수와 대여소 번호를 데이터 프레임으로 출력하라\n",
    "# 나이대별 대여구분 코드의 (일일권/전체횟수) 비율을 구한 후 가장 높은 비율을 가지는 나이대를 확인하라. 일일권의 경우 일일권 과 일일권(비회원)을 모두 포함하라\n",
    "# 연령대별 평균 이동거리를 구하여라\n",
    "# 연령대 코드가 20대인 데이터를 추출하고,이동거리값이 추출한 데이터의 이동거리값의 평균 이상인 데이터를 추출한다.최종 추출된 데이터를 대여일자, 대여소 번호 순서로 내림차순 정렬 후 1행부터 200행까지의 탄소량의 평균을 소숫점 3째 자리까지 구하여라\n",
    "# 6월 7일 ~10대의 “이용건수”의 중앙값은?\n",
    "# 평일 (월~금) 출근 시간대(오전 6,7,8시)의 대여소별 이용 횟수를 구해서 데이터 프레임 형태로 표현한 후 각 대여시간별 이용 횟수의 상위 3개 대여소와 이용횟수를 출력하라\n",
    "# 이동거리의 평균 이상의 이동거리 값을 가지는 데이터를 추출하여 추출데이터의 이동거리의 표본표준편차 값을 구하여라\n",
    "# 남성(‘M’ or ‘m’)과 여성(‘F’ or ‘f’)의 이동거리값의 평균값을 구하여라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45937bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df =pd.read_csv('https://raw.githubusercontent.com/Datamanim/datarepo/main/happy2/happiness.csv',encoding='utf-8')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03ed396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터는 2018년도와 2019년도의 전세계 행복 지수를 표현한다. 각년도의 행복랭킹 10위를 차지한 나라의 행복점수의 평균을 구하여라\n",
    "# 데이터는 2018년도와 2019년도의 전세계 행복 지수를 표현한다. 각년도의 행복랭킹 50위이내의 나라들의 각각의 행복점수 평균을 데이터프레임으로 표시하라\n",
    "# 2018년도 데이터들만 추출하여 행복점수와 부패에 대한 인식에 대한 상관계수를 구하여라\n",
    "# 2018년도와 2019년도의 행복랭킹이 변화하지 않은 나라명의 수를 구하여라\n",
    "# 2019년도 데이터들만 추출하여 각변수간 상관계수를 구하고 내림차순으로 정렬한 후 상위 5개를 데이터 프레임으로 출력하라. 컬럼명은 v1,v2,corr으로 표시하라\n",
    "# 각 년도별 하위 행복점수의 하위 5개 국가의 평균 행복점수를 구하여라\n",
    "# 2019년 데이터를 추출하고 해당데이터의 상대 GDP 평균 이상의 나라들과 평균 이하의 나라들의 행복점수 평균을 각각 구하고 그 차이값을 출력하라\n",
    "# 각년도의 부패에 대한인식을 내림차순 정렬했을때 상위 20개 국가의 부패에 대한인식의 평균을 구하여라\n",
    "# 2018년도 행복랭킹 50위 이내에 포함됐다가 2019년 50위 밖으로 밀려난 국가의 숫자를 구하여라\n",
    "# 2018년,2019년 모두 기록이 있는 나라들 중 년도별 행복점수가 가장 증가한 나라와 그 증가 수치는?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3938893",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df= pd.read_csv('https://raw.githubusercontent.com/Datamanim/datarepo/main/consum/Tetuan%20City%20power%20consumption.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d7d6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DateTime컬럼을 통해 각 월별로 몇개의 데이터가 있는지 데이터 프레임으로 구하여라\n",
    "# 3월달의 각 시간대별 온도의 평균들 중 가장 낮은 시간대의 온도를 출력하라\n",
    "# 3월달의 각 시간대별 온도의 평균들 중 가장 높은 시간대의 온도를 출력하라\n",
    "# Zone 1 Power Consumption 컬럼의 value값의 크기가 Zone 2  Power Consumption 컬럼의 value값의 크기보다 큰 데이터들의 Humidity의 평균을 구하여라\n",
    "# 각 zone의 에너지 소비량의 상관관계를 구해서 데이터 프레임으로 표기하라\n",
    "# Temperature의 값이 10미만의 경우 A, 10이상 20미만의 경우 B,20이상 30미만의 경우 C, 그 외의 경우 D라고 할때 각 단계의 데이터 숫자를 구하여라\n",
    "# 6월 데이터중 12시의 Temperature의 표준편차를 구하여라\n",
    "# 6월 데이터중 12시의 Temperature의 분산을 구하여라\n",
    "# Temperature의 평균이상의 Temperature의 값을 가지는 데이터를 Temperature를 기준으로 정렬 했을때 4번째 행의 Humidity 값은?\n",
    "# **Temperature의 중간값 이상의 Temperature의 값을 가지는 데이터를Temperature를 기준으로 정렬 했을때 4번째 행의 Humidity 값은? **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d7cbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/Datamanim/datarepo/main/pok/Pokemon.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab4d666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Legendary 컬럼은 전설포켓몬 유무를 나타낸다.전설포켓몬과 그렇지 않은 포켓몬들의 HP평균의 차이를 구하여라\n",
    "# Type 1은 주속성 Type 2 는 부속성을 나타낸다. 가장 많은 부속성 종류는 무엇인가?\n",
    "# 가장 많은 Type 1 의 종의 평균 Attack 을 평균 Defense로 나눈값은?\n",
    "# 포켓몬 세대(Generation) 중 가장많은 Legendary를 보유한 세대는 몇세대인가?\n",
    "# ‘HP’, ‘Attack’, ‘Defense’, ‘Sp. Atk’, ‘Sp. Def’, ‘Speed’ 간의 상관 계수중 가장 절댓값이 큰 두 변수와 그 값을 구하여라\n",
    "# 각 Generation의 Attack으로 오름차순 정렬시 상위 3개 데이터들(18개)의 Attack의 전체 평균을 구하여라\n",
    "# 각 Generation의 Attack으로 내림차순 정렬시 상위 5개 데이터들(30개)의 Attack의 전체 평균을 구하여라\n",
    "# 가장 흔하게 발견되는 (Type1 , Type2) 의 쌍은 무엇인가?\n",
    "# 한번씩만 존재하는 (Type1 , Type2)의 쌍의 갯수는 몇개인가?\n",
    "# 한번씩만 존재하는 (Type1 , Type2)의 쌍을 각 세대(Generation)은 각각 몇개씩 가지고 있는가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e23c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df =pd.read_csv('https://raw.githubusercontent.com/Datamanim/datarepo/main/body/body.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5595e573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체데이터의 수축기혈압(최고) - 이완기혈압(최저)의 평균을 구하여라\n",
    "# 50~59세의 신장평균을 구하여라\n",
    "# 연령대 (20~29 : 20대 …) 별  인원수를 구하여라\n",
    "# 연령대 (20~29 : 20대 …) 별 등급의 숫자를 데이터 프레임으로 표현하라\n",
    "# 남성 중 A등급과 D등급의 체지방률 평균의 차이(큰 값에서 작은 값의 차)를 구하여라\n",
    "# 여성 중 A등급과 D등급의 체중의 평균의 차이(큰 값에서 작은 값의 차)를 구하여라\n",
    "# bmi는 자신의 몸무게(kg)를 키의 제곱(m)으로 나눈값이다. 데이터의 bmi 를 구한 새로운 컬럼을 만들고 남성의 bmi 평균을 구하여라\n",
    "# bmi보다 체지방율이 높은 사람들의 체중평균을 구하여라\n",
    "# 남성과 여성의 악력 평균의 차이를 구하여라\n",
    "# 남성과 여성의 교차윗몸일으키기 횟수의 평균의 차이를 구하여라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b68cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/Datamanim/datarepo/main/weather/weather2.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6febd370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여름철(6월,7월,8월) 이화동이 수영동보다 높은 기온을 가진 시간대는 몇개인가?\n",
    "# 이화동과 수영동의 최대강수량의 시간대를 각각 구하여라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33542c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/Datamanim/datarepo/main/churn/train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c691c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 남성 이탈(Exited)이 가장 많은 국가(Geography)는 어디이고 이탈 인원은 몇명인가?\n",
    "# **카드를 소유(HasCrCard ==1)하고 있으면서 활성멤버(IsActiveMember ==1) 인 고객들의 평균 나이를 소숫점이하 4자리까지 구하여라? **\n",
    "# Balance 값이 중간값 이상을 가지는 고객들의 CreditScore의 표준편차를 소숫점이하 3자리까지 구하여라\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b893108b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/Datamanim/datarepo/main/smoke/train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5d70f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수축기혈압과 이완기 혈압기 수치의 차이를 새로운 컬럼(‘혈압차’) 으로 생성하고, 연령대 코드별 각 그룹 중 ‘혈압차’ 의 분산이 5번째로 큰 연령대 코드를 구하여라\n",
    "# 비만도를 나타내는 지표인 WHtR는 허리둘레 / 키로 표현한다. 일반적으로 0.58이상이면 비만으로 분류한다. 데이터중 WHtR 지표상 비만인 인원의 남/여 비율을 구하여라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d617aa34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/Datamanim/datarepo/main/insurance/train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b225af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vehicle_Age 값이 2년 이상인 사람들만 필터링 하고 그중에서 Annual_Premium 값이 전체 데이터의 중간값 이상인 사람들을 찾고, 그들의 Vintage값의 평균을 구하여라\n",
    "# vehicle_age에 따른 각 성별(gender)그룹의 Annual_Premium값의 평균을 구하여 아래 테이블과 동일하게 구현하라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6f3745",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/Datamanim/datarepo/main/mobile/train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0372d7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# price_range 의 각 value를 그룹핑하여 각 그룹의 n_cores 의 빈도가 가장높은 value와 그 빈도수를 구하여라\n",
    "# price_range 값이 3인 그룹에서 상관관계가 2번째로 높은 두 컬럼과 그 상관계수를 구하여라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c13d0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/Datamanim/datarepo/main/airline/train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00214c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrival Delay in Minutes 컬럼이 결측치인 데이터들 중 ‘neutral or dissatisfied’ 보다 ‘satisfied’의 수가 더 높은 Class는 어디 인가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a928c853",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/Datamanim/datarepo/main/waters/train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21b8095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ph값은 상당히 많은 결측치를 포함한다. 결측치를 제외한 나머지 데이터들 중 사분위값 기준 하위 25%의 값들의 평균값은?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521c0247",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv(\"https://raw.githubusercontent.com/Datamanim/datarepo/main/MedicalCost/train.csv\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835a1cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 흡연자와 비흡연자 각각 charges의 상위 10% 그룹의 평균의 차이는?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade3a0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/Datamanim/datarepo/main/kingcountyprice//train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce05798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bedrooms 의 빈도가 가장 높은 값을 가지는 데이터들의 price의 상위 10%와 하위 10%값의 차이를 구하여라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027238c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/Datamanim/datarepo/main/admission/train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81c16d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serial No. 컬럼을 제외하고 ‘Chance of Admit’을 종속변수, 나머지 변수를 독립변수라 할때, 랜덤포레스트를 통해 회귀 예측을 할 떄 변수중요도 값을 출력하라 (시드값에 따라 순서는 달라질수 있음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410a9e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/Datamanim/datarepo/main/redwine/train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c060f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quality 값이 3인 그룹과  8인 데이터그룹의 각 컬럼별 독립변수의 표준편차 값의 차이를 구할때 그값이 가장 큰 컬럼명을 구하여라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279fb767",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/Datamanim/datarepo/main/drug/train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933d6e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 남성들의 연령대별 (10살씩 구분 0~9세 10~19세 …) Na_to_K값의 평균값을 구해서 데이터 프레임으로 표현하여라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4445c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/Datamanim/datarepo/main/audit/train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3aeca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터의 Risk 값에 따른 score_a와 score_b의 평균값을 구하여라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce5a7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/Datamanim/datarepo/main/muscle/train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2735c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pose값에 따른 각 motion컬럼의 중간값의 가장 큰 차이를 보이는 motion컬럼은 어디이며 그값은?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3086e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/Datamanim/datarepo/main/hyundai/train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4337afc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정보(row수)가 가장 많은 상위 3차종의 price값의 각 평균값은?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c620b26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/Datamanim/datarepo/main/diabetes/train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5f702a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outcome 값에 따른 각 그룹의  각 컬럼의 평균 차이를 구하여라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cceee9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/Datamanim/datarepo/main/nflx/NFLX.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61b299a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 매년 5월달의 open가격의 평균값을 데이터 프레임으로 표현하라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17d25e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns',50)\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/Datamanim/datarepo/main/nba/nba.csv\",encoding='latin',sep=';')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc357aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tm 컬럼은 각 팀의 이름을 의미한다. TOR팀의 평균나이를 소수 4째 자리까지 구하여라\n",
    "# Pos 컬럼은 포지션을 의미한다. 전체 선수 중 최소나이대의 선수들을 필터하고 그들 중 가장 많은 포지션은 무엇인지 확인하라\n",
    "# 선수들의 이름은 first_name+ 공백 + last_name으로 이루어져 있다. 가장 많은 first_name은 무엇이며 몇 회 발생하는지 확인하라\n",
    "# PTS컬럼은 경기당 평균득점수 이다. 각포지션별로 경기당 평균득점수의 평균을 구하여라\n",
    "# PTS컬럼은 경기당 평균득점수 이다. 각포지션별로 경기당 평균득점수의 평균을 구하여라\n",
    "# G컬럼은 참여한 경기의 숫자이다. 각 팀별로 가장 높은 경기참여 수를 가진 선수들의 경기 참여 숫자의 평균을 구하여라\n",
    "# Tm의 값이 MIA이며 Pos는 C또는 PF인 선수의 MP값의 평균은?\n",
    "# 전체 데이터중 G의 평균값의 1.5배 이상인 데이터들만 추출했을때 3P값의 평균은?\n",
    "# Age의 평균 이상인 그룹과 평균 미만인 그룹간의 G값의 평균의 차이는?\n",
    "# 평균나이가 가장 젊은 팀은 어디인가\n",
    "# Pos그룹별 평균 MP값을 구하여라"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
